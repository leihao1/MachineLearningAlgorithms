{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract:\n",
    "This project is focusing on the (re-)implementation of all kinds of algorithms with python and spark.\n",
    "\n",
    "* Firstly,we comparing different strategies used in the same problem set to obtain more comprehensive understanding of every algorithm and get familar with their advantages and limitations.\n",
    "\n",
    "* Secondly,instead of applying one single algorithm in real life problems, we try to use as much as possible to take full advantage of them and to minimize the potential bias.\n",
    "\n",
    "* Moreover,to get a general solution when dealing with real life big data analysis, we wil break the boudary between different type of technology and treat them as basic brick blocks to build more powerful tools to sovle more complicated problem.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "### Recommender System\n",
    "\n",
    "A recommender system is the system recommending things to customers that they may interesred based on the prediction of algorithms to make more profit for the companies.\n",
    "\n",
    "We can implement this system by many kinds of algorithms such as content-based matrix, collaborative filtering and so forth, however the most well-known one should be the Netflix's one which was introduced since 2008.\n",
    "\n",
    "### Clustering\n",
    "\n",
    "Clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\n",
    "\n",
    "By clustering the data in groups we can make problems easy to solve.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Materials and Methods\n",
    "\n",
    "### Datasets:\n",
    "* [lab2_table.csv](./CollaborativeFiltering/lab2_table.csv)\n",
    "* [lab2_table_testset.csv](./CollaborativeFiltering/lab2_table_testset.csv)\n",
    "* [2dnormals.arff](./Clustering/datasets/2dnormals.arff)\n",
    "* [2d-20c-no0.arff](./Clustering/datasets/2d-20c-no0.arff)\n",
    "* [2sp2glob.arff](./Clustering/datasets/2sp2glob.arff)\n",
    "\n",
    "### Codes:\n",
    "* [CollaborativeFilter.py](./CollaborativeFiltering/CollaborativeFilter.py)\n",
    "* [k-means.py](./Clustering/k-means.py)\n",
    "\n",
    "### Method:\n",
    "\n",
    "##### [Recommender System ](https://github.com/leihao1/Mining-Massive-Datasets/blob/master/CollaborativeFiltering/Collaborative-Filtering.md)\n",
    "\n",
    ">Implement by basic item-item collaborative filtering and baseline+CF algorithm.\n",
    "\n",
    "##### [Clustering](https://github.com/leihao1/Mining-Massive-Datasets/blob/master/Clustering/K-Means.md)\n",
    "\n",
    ">Implement by kmeans algorithm.\n",
    ">\n",
    ">STEP 1: Select K\n",
    ">* Select the most suitable K value by system using 'elbow' method\n",
    ">* Select specific by user\n",
    ">\n",
    ">STEP 2: Pick initial K points(cluster centroid)\n",
    ">\n",
    ">* Sampling\n",
    ">* Dispersed(we use this one)\n",
    ">\n",
    ">STEP 3: Assigning every data points to K clusters by centroid distance\n",
    ">\n",
    ">STEP 4: Reset the centroid for each clusters and do STEP 3 again until clusters are stable(centroids do not move)\n",
    "\n",
    "# Results\n",
    "\n",
    "### Recommender System\n",
    "By basic collaborative filstering ,we can only get very few predictions since similar items not always be rated by same person. And it also has cold start problem and matrix sparse problem.\n",
    "\n",
    "To solve these problems ,we improved this algorithm by combining with baseline algorithm. \n",
    "\n",
    "Base on the dataset [lab2_table.csv](./CollaborativeFiltering/lab2_table.csv) and testset [lab2_table_testset.csv](./CollaborativeFiltering/lab2_table_testset.csv)(80% training set+20% test set), we got relatively lower RMSE.\n",
    "![C](./CollaborativeFiltering/N-RMSE.png)\n",
    "\n",
    "### Clustering\n",
    "K-means algorithm is useful but still has many limitations.\n",
    "\n",
    "We can get a good clustering in this kind of dataset.\n",
    "\n",
    "[2d-20c-no0.arff](./Clustering/datasets/2d-20c-no0.arff)\n",
    "![initial](./Clustering/figures/2d-20c-no0.arff1.png)\n",
    "![pick_k_points](./Clustering/figures/2d-20c-no0.arff2.png)\n",
    "![final_clusters](./Clustering/figures/2d-20c-no0.arff43.png)\n",
    "\n",
    "And this kind of dataset.\n",
    "\n",
    "[2dnormals.arff](./Clustering/datasets/2dnormals.arff)\n",
    "![initial](./Clustering/figures/2dnormals.arff1.png)\n",
    "![pick_k_points](./Clustering/figures/2dnormals.arff2.png)\n",
    "![final_clusters](./Clustering/figures/2dnormals.arff35.png)\n",
    "\n",
    "But when we deal with this kind of dataset , kmeans shows its limitation.\n",
    "\n",
    "[2sp2glob.arff1](./Clustering/datasets/2sp2glob.arff)\n",
    "![initial](./Clustering/figures/2sp2glob.arff1.png)\n",
    "![pick_k_points](./Clustering/figures/2sp2glob.arff2.png)\n",
    "![final_clusters](./Clustering/figures/2sp2glob.arff19.png)\n",
    "\n",
    "# TO DO:\n",
    "\n",
    "* Implement algorithms with spark to deal with big data\n",
    "* Improve recommender system by using ALS algorithm\n",
    "* Improve clustering algorithm with CURE to deal with all kind of dataset shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
